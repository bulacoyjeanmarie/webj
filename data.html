<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Web Journal</title>

    <!-- font awesome cdn link  -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">

    <!-- custom css file link  -->
    <link rel="stylesheet" href="style.css">


</head>

<body>
    <header class="header">

        <div class="user">
            <img src="image/profile.jpg" alt="">
            <h3>Jean Mae Marie</h3>
            <p>BS Info Tech Student 3A</p>
        </div>
    
        <nav class="navbar">
            <a href="webjournal.html">Go back</a>
            <a href="augmented.html">Preview</a>
            <a href="otheremergingtech.html">Next</a>
            
        
        </nav>
    
    </header>
    
    <div id="menu-btn" class="fas fa-bars"></div>

<div id="theme-toggler" class="fas fa-moon"></div>


<section class="portfolio" id="portfolio">

    <h1 class="heading"> What is <span>Data Science?</span> </h1>

    <div class="box-container">

<div class="box">
    <img src="image/dataScience.gif" alt="">
    <div class="content">
        <h3>Data Science</h3>
        <p>Data science is a multi-disciplinary field that uses scientific methods,
            processes, algorithms, and systems to extract knowledge and insights from
            structured, semi-structured and unstructured data. Data science is much
            more than simply analyzing data. It offers a range of roles and requires a
            range of skills.</p>
    </div>

</div>
    </div>

    <div class="morecontent">
        <h3>What are data and information?</h3>
        <br>
        <p><b>Data</b> can be defined as a representation of facts, concepts, or
            instructions in a formalized manner, which should be suitable for
            communication, interpretation, or processing, by human or electronic
            machines. It can be described as unprocessed facts and figures. It is
            represented with the help of characters such as alphabets (A-Z, a-z), digits
            (0-9) or special characters (+, -, /, *, <,>, =, etc.).</p>
        <br>
        <br>
        <p><b>Information</b> is the processed data on which decisions and actions are
            based. It is data that has been processed into a form that is meaningful to
            the recipient and is of real or perceived value in the current or the
            prospective action or decision of recipient.</p>
        <br>
        <br>
        <h4>Data Processing Cycle</h4>
        <br>
        <img src="image/data-processing-input-to-output-data-processing-cycle-100746655.jpg">
        <br>
        <br>
        <p><b>Input −</b>
             in this step, the input data is prepared in some convenient form for
            processing. The form will depend on the processing machine.</p>
        <br>
        <p><b>Processing −</b> in this step, the input data is changed to produce data in a
            more useful form.</p>
        <br>
        <p><b>Output −</b> at this stage, the result of the proceeding processing step is
            collected. The particular form of the output data depends on the use of the
            data.</p>
        <br>
        <br>
        <h4>Data types and their representation</h4>
        <br>
        <p>Data types can be described from diverse perspectives. In computer
            science and computer programming, for instance, a data type is simply an
            attribute of data that tells the compiler or interpreter how the programmer
            intends to use the data.</p>
        <br>
        <h4>Data types from Computer Programming Perspective</h4>
        <br>
            <li><b>Integers(int)</b> - is used to store whole numbers, mathematically known as
                integers.</li>
            <li><b>Booleans(bool)</b> - is used to represent restricted to one of two values: true
                or false.</li>
            <li><b>Characters(char)</b> - is used to store a single character.</li>
            <li><b>Floating-point numbers(float)</b> - is used to store real numbers.</li>
            <li><b>Alphanumeric strings(string)</b> - used to store a combination of characters
                and numbers.</li>
                <br>
                <br>

        <h3>Data Types from Data AnalyticsPerspective</h3>
        <br>
        <p><b>Structured Data</b></p>
        <br>
        <p>Is data that adheres to a per-defined data model
            and is therefore straightforward to analyze.
            Structured data conforms to a tabular format with
            a relationship between the different rows and
            columns.</p>
        <br>
        <p><b>Semi-structured</b></p>
        <br>
        <p>Is a form of structured data that does not conform with
            the formal structure of data models associated with
            relational databases or other forms of data tables, but
            nonetheless, contains tags or other markers to separate
            semantic elements and enforce hierarchies of records
            and fields within the data.</p>
        <br>
        <p><b>Unstructured Data</b></p>
        <br>
        <p>Is information that either does not have a predefined data
            model or is not organized in a pre-defined manner.
            Unstructured information is typically text-heavy but may
            contain data such as dates, numbers, and facts as well.
            This results in irregularities and ambiguities that make it
            difficult to understand using traditional programs as
            compared to data stored in structured databases.</p>
        <br>
        <img src="image/struc.png">
        <br>
        <h4>Metadata-Data
            about Data</h4>
        <br>
        <p>The last category of data type is metadata. From a
            technical point of view, this is not a separate data
            structure, but it is one of the most important elements
            for Big Data analysis and big data solutions. Metadata
            is data about data. It provides additional information
            about a specific set of data.</p>
        <br>
        <h3>Data Value Chain</h3>
        <br>
        <p>The Data Value Chain is introduced to describe the information flow
            within a big data system as a series of steps needed to generate value
            and useful insights from data. The Big Data Value Chain identifies the
            following key high-level activities:</p>
        
        <br>
        <img src="image/Screenshot 2023-04-02 7.08.19 PM.png">


    </div>
   
</section>

<section class="portfolio" id="portfolio">
    <div class="morecontent">
        <h3>Big Data</h3>
        <br>
        <p><b>Big data</b> is a blanket term for the non-traditional
            strategies and technologies needed to gather, organize,
            process, and gather insights from large datasets. While the
            problem of working with data that exceeds the computing
            power or storage of a single computer is not new, the
            pervasiveness, scale, and value of this type of computing
            have greatly expanded in recent years.</p>
        <br>
        <p><b>Big data</b> is the term for a collection of data sets so large and
            complex that it becomes difficult to process using on-hand
            database management tools or traditional data processing
            applications.
            <br>
            <br>
            In this context, a “large dataset” means a dataset too large to
            reasonably process or store with traditional tooling or on a single
            computer. This means that the common scale of big datasets is
            constantly shifting and may vary significantly from organization to
            organization. Big data is characterized by 3V and more:</p>
            <br>
                <li><b>Volume:</b> large amounts of data Zeta bytes/Massive
                    datasets</li>
                <li><b>Velocity</b> Data is live streaming or in motion</li>
                <li><b>Variety:</b> data comes in many different forms from
                    diverse sources</li>
                <li><b>Veracity:</b> can we trust the data? How accurate is it?
                    etc.</li>
            <br>
            <img src="image/Screenshot 2023-04-02 7.25.07 PM.png">
    </div>
</section>

<section class="portfolio" id="portfolio">
    <div class="morecontent">
        <h3>Clustered Computing and
            Hadoop Ecosystem</h3>
        <br>
        <br>
        <h4>Clustered Computing</h4>
            <li>Cluster computing is a form of computing in which a group
                of computers are linked together so that they can <b>act like a
                single entity.</b></li>
            <li>It is the technique of linking two or more computers into a
                network (usually through a local area network) in order to
                take advantage of the <b>parallel processing power of those
                computers.</b></li>
        <br>
        <br>
        <p>Big data clustering software combines the resources of many smaller
            machines, seeking to provide a number of benefits:</p>
        <br>
            <li><b>Resource Pooling:</b> Combining the available storage space to hold data is a
                clear benefit, but CPU and memory pooling are also extremely important.
                Processing large datasets requires large amounts of all three of these
                resources.</li>
            <li><b>High Availability:</b> Clusters can provide varying levels of fault tolerance and
                availability guarantees to prevent hardware or software failures from affecting
                access to data and processing. This becomes increasingly important as we
                continue to emphasize the importance of real-time analytics.</li>
            <li><b>Easy Scalability:</b> Clusters make it easy to scale horizontally by adding
                additional machines to the group. This means the system can react to
                changes in resource requirements without expanding the physical resources
                on a machine.</li>
            <br>
            <br>
            <h3>Hadoop and its Ecosystem</h3>
            <p>Hadoop is an open-source framework intended to
                make interaction with big data easier. It is a
                framework that allows for the distributed processing
                of large datasets across clusters of computers using
                simple programming models. It is inspired by a
                technical document published by Google.</p>
            <br>
            <h4>The four key characteristics of Hadoop are:</h4>
            <br>
                <li><b>Economical:</b> Its systems are highly economical as ordinary
                    computers can be used for data processing.</li>
                <li><b>Reliable:</b> It is reliable as it stores copies of the data on different
                    machines and is resistant to hardware failure.</li>
                <li><b>Scalable:</b> It is easily scalable both, horizontally and vertically. A
                    few extra nodes help in scaling up the framework.</li>
                <li><b>Flexible:</b> It is flexible and you can store as much structured and
                    unstructured data as you need to and decide to use them later.</li>
                <br>
                <br>
                <h3>Big Data Life Cycle with Hadoop</h3>
                <br>
                <h4><b>Ingesting data into the system</b></h4>
                <br>
                <p>The first stage of Big Data processing is Ingest. The data is
                    ingested or transferred to Hadoop from various sources such as
                    relational databases, systems, or local files. Sqoop transfers data
                    from RDBMS to HDFS, whereas Flume transfers event data.</p>
                <br>
                <h4>Processing the data in storage</h4>
                <br>
                <p>The second stage is Processing. In this stage, the data is
                    stored and processed. The data is stored in the distributed
                    file system, HDFS, and the NoSQL distributed data, HBase.
                    Spark and MapReduce perform data processing.</p>
                <br>
                <h4>Computing and analyzing data</h4>
                <br>
                <p>The third stage is to Analyze. Here, the data is analyzed by
                    processing frameworks such as Pig, Hive, and Impala. Pig
                    converts the data using a map and reduce and then
                    analyzes it. Hive is also based on the map and reduce
                    programming and is most suitable for structured data.</p>
                <br>
                <h4>Visualizing the results</h4>
                <br>
                <p>The fourth stage is Access, which is performed by tools
                    such as Hue and Cloudera Search. In this stage, the
                    analyzed data can be accessed by users.</p>



    </div>

</section>

<div class="credits"> created by <span>ms. Jean</span> | all rights reserved </div>


<script src="script.js"></script>

</body>
</html>
